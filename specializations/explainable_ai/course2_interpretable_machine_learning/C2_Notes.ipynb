{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Interpretable Machine Learning](#toc0_)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Interpretable Machine Learning](#toc1_)    \n",
    "- [Module 1️⃣](#toc2_)    \n",
    "  - [Introduction to Interpretable ML](#toc2_1_)    \n",
    "  - [Regression Models](#toc2_2_)    \n",
    "    - [Linear Regression](#toc2_2_1_)    \n",
    "      - [Pros & Cons](#toc2_2_1_1_)    \n",
    "      - [Assumptions](#toc2_2_1_2_)    \n",
    "    - [Logistic Regression](#toc2_2_2_)    \n",
    "      - [Assumptions](#toc2_2_2_1_)    \n",
    "      - [Logistic Function](#toc2_2_2_2_)    \n",
    "      - [Logit Function](#toc2_2_2_3_)    \n",
    "      - [Log Odds](#toc2_2_2_4_)    \n",
    "      - [Pros & Cons](#toc2_2_2_5_)    \n",
    "  - [Generalized (Linear) Model](#toc2_3_)    \n",
    "    - [Generalized Additive Models](#toc2_3_1_)    \n",
    "- [Module 2️⃣](#toc3_)    \n",
    "  - [Decision Trees](#toc3_1_)    \n",
    "    - [CART](#toc3_1_1_)    \n",
    "      - [Implementation](#toc3_1_1_1_)    \n",
    "        - [Variance](#toc3_1_1_1_1_)    \n",
    "        - [Gini Index](#toc3_1_1_1_2_)    \n",
    "      - [Interpreting CART](#toc3_1_1_2_)    \n",
    "    - [Sparse Decision Trees](#toc3_1_2_)    \n",
    "  - [Decision Rules and RuleFit](#toc3_2_)    \n",
    "  - [Neural Network Interpretability](#toc3_3_)    \n",
    "- [Resources](#toc4_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Module 1️⃣](#toc0_)\n",
    "\n",
    "**Learning Objectives**\n",
    "- Describe interpretable machine learning and differentiate between interpretability and explainability.\n",
    "- Explain and implement regression models in Python.\n",
    "- Demonstrate knowledge of generalized models in Python.\n",
    "\n",
    "## <a id='toc2_1_'></a>[Introduction to Interpretable ML](#toc0_)\n",
    "**Interpretability**\n",
    "> An interpretable model provides both visibility into its mechanisms and insiht into how it arrives at its predictions. Provides insights into what features are important, how they are related, or what rules/patterns are learned \n",
    ">\n",
    "> *Examples:* Inherently interpretable models - Decision Trees, Monotonic NNs\n",
    "\n",
    "## <a id='toc2_2_'></a>[Regression Models](#toc0_)\n",
    "### <a id='toc2_2_1_'></a>[Linear Regression](#toc0_)\n",
    "> The goal of Lin Reg is to create a linear model that minimizes the sum of squared residuals. \n",
    "\n",
    "$$\n",
    "    SSE = \\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2\n",
    "$$\n",
    "\n",
    "**Ordinary Least Squares**\n",
    "> goal is to find the line or hyperplane in higher dimensions that best fits the observable data points by minimizing the sum of squared residuals.\n",
    "\n",
    "- Relies on several assumptions: \n",
    "  1. relationship between the predictors and outcomes is linear\n",
    "  2. Observations are independent of one another.\n",
    "  3. Residuals have constant variance across all levels of predictors = homoscedasticity\n",
    "  4. Residuals are normally distributed\n",
    "\n",
    "**Regression**\n",
    "> A methodology used for modeling and analysis of numerical data.\n",
    ">\n",
    "> - relationships between 2+ variables are evaluated\n",
    "\n",
    "<img src=\"imgs/regression_formula.png\" alt=\"Sources of Bias\" width=\"400\">\n",
    "\n",
    "$$\n",
    "    y = \\beta_0 + \\beta_1 X_1 + \\dots + \\beta_j X_j + \\epsilon\n",
    "$$\n",
    "\n",
    "**How to interpret the coefficients $\\beta$?**\n",
    "- $\\pm$: \n",
    "  - indicates whether the associated feature has a positive or negative relationship with the target variable.\n",
    "- magnitude: \n",
    "  - represents the strength of that relationship. \n",
    "  - Larger coefficients indicate a stronger influence of that feature on the target variable.\n",
    "\n",
    "**Feature importance of features in Lin Reg:**\n",
    "> = absolute value of the features t-statistic\n",
    ">\n",
    "> t-statistic = estimated weight scaled with its standard error.\n",
    "\n",
    "$$\n",
    "  t_{\\hat{\\beta_j}} = \\frac{\\hat{\\beta_j}}{SE(\\hat{\\beta_j})}\n",
    "$$\n",
    "\n",
    "- **Effect Plot**\n",
    "  - calculate the effects, which is the weight per feature times the feature value of an instance\n",
    "\n",
    "#### <a id='toc2_2_1_1_'></a>[Pros & Cons](#toc0_)\n",
    "\n",
    "| Pros | Cons |\n",
    "|------|------|\n",
    "| How predictions are produced is transparent | Can only represent linear relationships |\n",
    "| Lots of documnetation, used widely across domains | Usually not as accurate because the real world is complex and nonlinear |\n",
    "| Based on solid statistical theory | The interpretation of a weight is dependent on other features |\n",
    "\n",
    "#### <a id='toc2_2_1_2_'></a>[Assumptions](#toc0_)\n",
    "- Linearity (lin relationship between $X$ and $y$)\n",
    "- Independence (observations are independent to one another)\n",
    "- Homoscedasticity (variance of the residual errors is constant across all values of the independent variables)\n",
    "- Normality (residual errors follow $\\mathcal{N}$)\n",
    "- No multicollinearity (independent variables should not be highly correlated with each other)\n",
    "- No autocorrelation (the residual errors are not correlated with each other)\n",
    "- No endogeneity (independent variables are not correlated with the error term)\n",
    "\n",
    "### <a id='toc2_2_2_'></a>[Logistic Regression](#toc0_)\n",
    "> wraps lin reg eq in a logistic fct. \n",
    "> \n",
    "> - squeezes outputs on lin reg to $[0, 1]$.\n",
    "> - = lin model for the log odds \n",
    "\n",
    "- **log-odds**\n",
    "  - **odds** = probability or likelihood of a particular outcome\n",
    "    - e.g. $\\mathbb{P}$ of binary class $1$\n",
    "\n",
    "$$\n",
    "  ln( \\underbrace{\\frac{\\mathbb{P}(y=1)}{1 - \\mathbb{P}(y=1)})}_{\\text{Odds}} = \\underbrace{log(\\frac{\\mathbb{P}(y=1)}{\\mathbb{P}(y=0)})}_{LogOdds} = \\beta_0 + \\beta_1x_1 + \\dots + \\beta_p x_p \n",
    "  \\\\\n",
    "  \\frac{\\mathbb{P}(y=1)}{1 - \\mathbb{P}(y=1)}) = Odds = exp(\\beta_0 + \\beta_1x_1 + \\dots + \\beta_p x_p)\n",
    "$$\n",
    "\n",
    "#### <a id='toc2_2_2_1_'></a>[Assumptions](#toc0_)\n",
    "- Linearity \n",
    "- No multicollinearity \n",
    "- Independence of observations \n",
    "- No influential outliers \n",
    "- Absence of perfect separation\n",
    "- Large sample size\n",
    "\n",
    "#### <a id='toc2_2_2_2_'></a>[Logistic Function](#toc0_)\n",
    "> used to model the probability of a binary outcome in logistic regression. \n",
    "> \n",
    "> transforms the linear combination of the input features into a probability value 0-1. \n",
    "\n",
    "$$\n",
    "  \\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "#### <a id='toc2_2_2_3_'></a>[Logit Function](#toc0_)\n",
    "> inverse of the logistic function. \n",
    "> \n",
    "> transforms the probability of the binary outcome back into the log odds, a linear scale\n",
    "\n",
    "$$\n",
    "logit(p) = log(\\frac{p}{1-p})\n",
    "$$\n",
    "\n",
    "#### <a id='toc2_2_2_4_'></a>[Log Odds](#toc0_)\n",
    "> logarithm of the odds of the probability of an event occurring.\n",
    "> \n",
    "> The odds themselves are the ratio of the probability of the event occurring to the probability of the event not occurring. \n",
    ">\n",
    "> - Odds > 1 = positive\n",
    "> - Odds < 1 = negative\n",
    "\n",
    "$$\n",
    "  LogOdds = log(\\frac{p}{1-p})\n",
    "$$\n",
    "\n",
    "#### <a id='toc2_2_2_5_'></a>[Pros & Cons](#toc0_)\n",
    "\n",
    "| Pros | Cons |\n",
    "|------|------|\n",
    "| How predictions are produced is transparent | Can only represent linear relationships |\n",
    "| Lots of documnetation, used widely across domains | Usually not as accurate because the real world is complex and nonlinear |\n",
    "| Based on solid statistical theory | Interpretation more difficult than lin reg because the interpreation of the weights is multiplicative and not additive | \n",
    "| Can give you probabilities in addition to classification | If there is a feature that would perfectly separate the two classes, the weight for that feature would not converge and the model wouldn't be able to be trained. Because the optimal weight would be infinite. | \n",
    "\n",
    "\n",
    "\n",
    "## <a id='toc2_3_'></a>[Generalized (Linear) Model](#toc0_)\n",
    "\n",
    "> Idea: Keep the weighted sum of the features, but allow non-Gaussian outcome distributions and connect the expected mean of this distribution and the weighted sum through a possibly nonlinear function.\n",
    "\n",
    "$$\n",
    "  \\overbrace{g}^{\\text{link function}} ( \\underbrace{\\mathbb{E}_Y(y|x)}_{\\text{probability distribution from the exponential famility that defines} \\; E_Y} ) = x^T\\beta\n",
    "$$\n",
    "\n",
    "- If target outcome does not follow a Gaussian distribution\n",
    "- Logistic regression\n",
    "  - is a GLM that assumes the Bernoullu distribution and uses the logit function as its link function\n",
    "\n",
    "| Pros | Cons |\n",
    "|------|------|\n",
    "| How predictions are produced is transparent | Most modifications of the linear model make the model less interpretable | \n",
    "| Lots of documentation, used widely across domains | Any link function complicates interpretation|\n",
    "| Based on solid statistical theory | | \n",
    "| Allows modeling of non-Gaussian outcomes | |\n",
    "\n",
    "### <a id='toc2_3_1_'></a>[Generalized Additive Models](#toc0_)\n",
    ">  if the relationship between our features and outcome is not linear\n",
    "\n",
    "*If the relationship between our features and outcome is not linear?* we could \n",
    "- transform feature\n",
    "- categorize feature\n",
    "- use GAMs\n",
    "\n",
    "$$\n",
    "  f(\\mathbb{E}_Y(y|x)) = \\beta_0 + f_1(x_1) + f_2(x_2) + \\dots + f_p(x_p)\n",
    "$$\n",
    "\n",
    "- We can learn the functions $f$ by using *Spline Functions*\n",
    "> **Splines** are constructed from simpler basis functions, and used to approximate more complex functions\n",
    "\n",
    "| Pros | Cons |\n",
    "|------|------|\n",
    "| How predictions are produced is transparent | Most modifications of the linear model make the model less interpretable | \n",
    "| Lots of documentation, used widely across domains | | \n",
    "| Based on solid statistical theory | | \n",
    "| Allows nonlinear relationships to be modeled | |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[Module 2️⃣](#toc0_)\n",
    "\n",
    "**Learning Objectives**\n",
    "- Explain and implement decision trees in Python.\n",
    "- Demonstrate knowledge of decision rules in Python.\n",
    "- Define and explain neural network interpretable model approaches, including prototype-based networks, monotonic networks, and Kolmogorov-Arnold networks.\n",
    "\n",
    "## <a id='toc3_1_'></a>[Decision Trees](#toc0_)\n",
    "> Tree-based models split the data multiple times based on certain cutoff values in the features.\n",
    "\n",
    "### <a id='toc3_1_1_'></a>[CART](#toc0_)\n",
    "> = Classification & Regression Trees\n",
    "\n",
    "$$\n",
    "    \\hat{y} = \\hat{f}(x) = \\sum_{m=1}^{M} c_m I\\{x \\in R_m\\}\n",
    "$$\n",
    "\n",
    "- $\\hat{y}=$ predicted value for a given instance $x$\n",
    "- $x=$ instance\n",
    "- $M=$ total number of leaf nodes (or subsets) in the model\n",
    "- $R_m=$ subset (leaf node), each instance $x$ falls into one subset\n",
    "- $c_m=$ constant value associated with the $m$-th leaf node $R_m$\n",
    "- $I_{\\{ x \\in R_m \\}}=$ is the function that returns $1$ if $x$ is in the subset $R_m$ and $0$ otherwise\n",
    "\n",
    "#### <a id='toc3_1_1_1_'></a>[Implementation](#toc0_)\n",
    "The implementation of the CART algorithm starts with the \n",
    "- splitting of the data into different subsets based on feature values. \n",
    "- CART determines the cutoff point for a feature that ... of the target variable.\n",
    "  - ... minimizes the variance for regression, or \n",
    "  - ... Gini index for classification \n",
    "- This process of splitting is done recursively. \n",
    "- At each node, the algorithm selects the best feature and the best value of that feature to split the data, \n",
    "  - based on some criterion like the \n",
    "    - Gini impurity for classification or the \n",
    "    - MSE for regression. \n",
    "\n",
    "##### <a id='toc3_1_1_1_1_'></a>[Variance](#toc0_)\n",
    "> measures how spread out the target values are around the mean in a node. \n",
    "\n",
    "##### <a id='toc3_1_1_1_2_'></a>[Gini Index](#toc0_)\n",
    "> measures the impurity or class distribution in a node\n",
    "\n",
    "#### <a id='toc3_1_1_2_'></a>[Interpreting CART](#toc0_)\n",
    "> If your instance lies in the subset (leaf node), the predicted outcome is the mean value of $y$ of the instances in that node\n",
    "\n",
    "- If we want to examine feature importance, we look at all the splits for which the feature was used, measure how much it has reduced the variance or Gini index compared to the parent node.\n",
    "- The sum of all importances is scaled to $100$, so each importance can be interpreted as share of the overall model importance.\n",
    "\n",
    "| Pros | Cons |\n",
    "|------|------|\n",
    "| Great for capturing interactions between features in the data | Trees don't deal well with linear relationships (they create step functions, which are inefficient) |\n",
    "| A natural visualization | Unstable (Small changes in the training dataset can create a completely different tree. Why? Because each split depends on the parent split.) | \n",
    "| You can use features without any transformations | As trees get larger, they become harder to interpret | \n",
    "\n",
    "### <a id='toc3_1_2_'></a>[Sparse Decision Trees](#toc0_)\n",
    "\n",
    "**GOSDT** = generalized and scalable optimal sparse decision trees\n",
    "- Solves the problem of Decision Trees: \n",
    "  - DTs are created from the top down and pruned. This means that if you make a mistake at the top, that will propagate through your whole model.\n",
    "- *Idea*: \n",
    "  - Minimize an objective that is a function of tree and data over all possible trees you can construct on this data. \n",
    "  - We want to minimize both the \n",
    "    - misclassification error and the \n",
    "    - number of leaves to encourage sparsity and thus interpretability.\n",
    "- Can be summarized into *Branch and Bound* (= idea is reducing the search space of all DTs)\n",
    "  - Analytical bounds help in efficiently pruning the search space\n",
    "    1. **Hierarchical Objective Lower Bound** \n",
    "       - If $R_{bestSoFar} < b(tree_{fixed})$ then this tree and its children are all suboptimal \n",
    "    2. **Hierarchical Objective Lower Bound with Lookahead**\n",
    "       - If $R_{bestSoFar} < b(tree_{fixed}) + C$ (our tree with at least one child) then this tree & chuildren are suboptimal\n",
    "    3. **Leaf Bound**\n",
    "       - Max # leaves of any optimal child tree $< \\# leaves(tree) + (R_{bestSoFar} - b(tree))/C$\n",
    "    4. **Incremental Progress Bound(s)**\n",
    "       - Each split must provide a reduction in loss of at least $C$ \n",
    "- Scalable, due to its bit vector representation, which represents each sub-problem by its contents as bit vectors\n",
    "\n",
    "## <a id='toc3_2_'></a>[Decision Rules and RuleFit](#toc0_)\n",
    "\n",
    "> = simple IF-THEN statements consisting of a condition and a prediction learned through an algorithm.\n",
    "\n",
    "One important concept when implementing decision rules is the trade off between coverage and support and accuracy in confidence.\n",
    "- **Coverage/Support**\n",
    "  - Percentage of instances to which the condition of a rule applies.\n",
    "- **Accuracy**\n",
    "  - Measure of how accurate the rule is in predicting the correct class for the instances to which the condition of the rule applies. \n",
    "\n",
    "Algorithms for learning rules: \n",
    "- **OneR**\n",
    "  - From all the features, OneR selected the one that carries the most information about the outcome of interest and creates decision rules from this feature.\n",
    "- **Sequential Covering**\n",
    "  - A general procedure that iteratively learns rules and removes the data points that are covered by the new rule.\n",
    "\n",
    "| Pros | Cons | \n",
    "|------|------|\n",
    "| Very easy to interpret | Mostly used only for classification |\n",
    "| More compact than decision trees | Features need to be categorical | \n",
    "| Prediction is fast | Some algorithms are prone to overfitting | \n",
    "| Usually automatically generate sparse models | Don't deal well with linear relationships (they create step functions, which are inefficient) | \n",
    "\n",
    "- **RuleFit**\n",
    "  - Combines decision trees with linear models by generating rules from an ensemble of decision trees and then fitting a sparse linear model on those rules\n",
    "  - Learns sparse linear model with the original features AND also a number of new features that are decision rules.\n",
    "  - [Steps](https://www.coursera.org/learn/interpretable-machine-learning/lecture/53KLa/rulefit)\n",
    "    1. Generate Rules\n",
    "    2. Create Sparse Linear Model\n",
    "\n",
    "| Pros | Cons | \n",
    "|------|------|\n",
    "| Easy to interpret | Interpretability worsens with increasing number of features in the model. |\n",
    "| Adds feature interactions to linear models. | Interpretation is tricky for overlapping rules. | \n",
    "| Works for both classification and regression |  | \n",
    "\n",
    "## <a id='toc3_3_'></a>[Neural Network Interpretability](#toc0_)\n",
    "\n",
    "<img src=\"imgs/types_of_interpretable_nns.png\" alt=\"Sources of Bias\" width=\"400\">\n",
    "\n",
    " Improved interpretability in neural networks comes in the form of \n",
    " - **shallow neural networks**,\n",
    "   - simpler neural network architectures with fewer layers and nodes that can be more interpretable than deeper and more complex models\n",
    "   - The relationships between inputs and outputs are more readily apparent\n",
    " - **sparse neural networks**, and \n",
    "   - models that have many network connections pruned or set to zero, and they can be more interpretable as the remaining connections represent the most important features\n",
    " - **modular neural networks**.\n",
    "   - models composed of specialized subcomponents, for example, object detection or classification or reasoning. These can be more interpretable than monolithic architectures.\n",
    "\n",
    "But there are also inherently interpretable models:\n",
    "- **disentangled neural networks**, \n",
    "  - models that learn representations where each neuron or feature map corresponds to a specific interpretable concept, like edges, textures, or object parts\n",
    "  - this can provide visibility into the model's internal reasonin\n",
    "- **prototype based neural networks**, and \n",
    "  - models that learn prototypical examples of each class and use similarity to these prototypes as the basis for predictions, \n",
    "  - this can be more interpretable than complex decision boundaries\n",
    "- **monotonic neural networks**\n",
    "  - models that constrain the neural network to produce outputs that are monotonically increasing or decreasing with respect to the input features\n",
    "  - this can make the model's behavior more intuitive and predictable\n",
    "\n",
    "### PotoPNet\n",
    "> = Prototype-based Neural Networks\n",
    "\n",
    "- Prototype-based explanations aim to explain the predictions of a black box model by identifying representative examples or prototypes from the data. \n",
    "- The main thesis is that we represent the model's knowledge in terms of prototypical instances or patterns.\n",
    "\n",
    "\n",
    "### MonoNet\n",
    "> = Monotonic Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc4_'></a>[Resources](#toc0_)\n",
    "\n",
    "- [Interpretable Machine Learning: Fundamental\n",
    "Principles and 10 Grand Challenges](https://arxiv.org/pdf/2103.11251)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
